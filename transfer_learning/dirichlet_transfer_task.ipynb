{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5cc745aa-416d-403d-adfc-64de45e6c488",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87ebffda-c2f3-4886-b702-23daf77c6cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2fef378b-0587-48f1-8e1f-479eba513d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE_TRAIN = 100\n",
    "BATCH_SIZE_VAL = 100\n",
    "BATCH_SIZE_TEST = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b1f29f0-d596-42f2-956c-3640d5fd2ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = torchvision.datasets.MNIST('./', train=True, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,))\n",
    "                             ]))\n",
    "testset = torchvision.datasets.MNIST('./', train=False, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,))\n",
    "                             ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "49a20b70-c3d1-499b-bfa8-c84afac9689e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "31980a5d-2b79-4e96-b5ab-e99a29c12d40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a013f11d-7dd5-4ccb-a99a-6a09d4821da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_subset, val_subset = torch.utils.data.random_split(\n",
    "        trainset, [50000, 10000], generator=torch.Generator().manual_seed(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5f3e5e7f-333b-4cbd-8354-34741a7065cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset=train_subset, shuffle=True, batch_size=BATCH_SIZE_TRAIN)\n",
    "val_loader = DataLoader(dataset=val_subset, shuffle=False, batch_size=BATCH_SIZE_VAL)\n",
    "test_loader = DataLoader(dataset=testset, shuffle=False, batch_size=BATCH_SIZE_TEST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f82556b2-223a-4aa0-b99b-be315ba347fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, dataset, batch_size=100, max_ex=0):\n",
    "    \"\"\"\n",
    "    evaluate for dirichlet does not calculate the mean of the distribution since the mean is proportional to alpha_i.\n",
    "    i.e., the probability with the highest mean = probability with highest alpha_i\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    acc = 0\n",
    "    N = len(dataset) * batch_size\n",
    "    for i, (features, labels) in enumerate(dataset):\n",
    "        features = features.double()\n",
    "        features = features.view(batch_size, -1)\n",
    "        features = features.to(device)\n",
    "        labels = labels.to(device)\n",
    "        scores = model(features)\n",
    "        # print(labels)\n",
    "        # print(scores)\n",
    "        pred = torch.argmax(scores, dim=1)\n",
    "        acc += torch.sum(torch.eq(pred, labels)).item()\n",
    "        if max_ex != 0 and i >= max_ex:\n",
    "            break\n",
    "    # print(i)\n",
    "    return (acc * 100 / ((i+1) * batch_size) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d6dfa986-e813-4d52-ad65-7d08b8088768",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_squared_error(teacher_output_prob, student_output_alpha):\n",
    "    output = student_output_alpha / torch.sum(student_output_alpha, dim=1, keepdim=True)\n",
    "    return F.mse_loss(teacher_output_prob, output).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c57658a1-ec8d-4b00-bb84-a98d8ac54bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TeacherModel(nn.Module):\n",
    "    def __init__(self, dropout=0.5):\n",
    "        super(TeacherModel, self).__init__()\n",
    "        self.linear1 = nn.Linear(784, 1200, dtype=torch.float64)\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        self.linear2 = nn.Linear(1200, 1200, dtype=torch.float64)\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        self.linear3 = nn.Linear(1200, 10, dtype=torch.float64)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.linear1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.linear2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.linear3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e01ff1cf-12f9-4390-8c05-a8cf35aa9cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 10\n",
    "lr = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ce2f509b-f832-48bf-ad3a-e83b28db4402",
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_model = TeacherModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "63157d7d-8a5f-4ed2-805f-1db0be86c55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = Adam(teacher_model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "df8f0848-0209-4f17-b9d1-5552bee2b3d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.303287425700386\n",
      "Loss: 0.30852745333251136\n",
      "Loss: 0.32154546260819733\n",
      "Loss: 0.21399600120998166\n",
      "Loss: 0.29092894384608675\n",
      "Loss: 0.079235226919389\n",
      "Loss: 0.13370553588615477\n",
      "Loss: 0.1463429162356006\n",
      "Loss: 0.1101149493041377\n",
      "Loss: 0.19215927272523398\n",
      "Loss: 0.13721820871697024\n",
      "Loss: 0.1548088120899069\n",
      "Loss: 0.12144178103976695\n",
      "Loss: 0.036790668936964414\n",
      "Loss: 0.1356627635968576\n",
      "Loss: 0.08432089876704037\n",
      "Loss: 0.09190448342900026\n",
      "Loss: 0.19988806582759366\n",
      "Loss: 0.1341253921082884\n",
      "Loss: 0.09667001996075535\n",
      "Loss: 0.14091394733867976\n",
      "Loss: 0.1922969484298019\n",
      "Loss: 0.06631771430028652\n",
      "Loss: 0.07075102954024037\n",
      "Loss: 0.10321670422037885\n",
      "Loss: 0.0788475945244516\n",
      "Loss: 0.04844425849865379\n",
      "Loss: 0.13565104304835304\n",
      "Loss: 0.061478311009363844\n",
      "Loss: 0.09436288340114134\n",
      "Loss: 0.11450734491835629\n",
      "Loss: 0.06349670687926358\n",
      "Loss: 0.050485011909864735\n",
      "Loss: 0.11003119429740518\n",
      "Loss: 0.11453528878319831\n",
      "Loss: 0.04007923529414313\n",
      "Loss: 0.19777858059428893\n",
      "Loss: 0.2912708154669698\n",
      "Loss: 0.14490289569778514\n",
      "Loss: 0.11606653031872362\n",
      "Loss: 0.08109644632553686\n",
      "Loss: 0.02335426392321046\n",
      "Loss: 0.06317920816598568\n",
      "Loss: 0.04630363452219452\n",
      "Loss: 0.1048175007788637\n",
      "Time taken:86.41724681854248\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "teacher_model.to(device)\n",
    "teacher_model.train()\n",
    "for epoch in range(1, NUM_EPOCHS):\n",
    "    for i, (data, target) in enumerate(train_loader):\n",
    "        data = data.double()\n",
    "        data = data.view(BATCH_SIZE_TRAIN, -1)\n",
    "        data = data.to(device)\n",
    "        target = target.to(device)\n",
    "        \n",
    "        output = teacher_model(data)\n",
    "        loss = criterion(output, target)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if i % 100 == 0:\n",
    "            print(\"Loss:\", loss.item())\n",
    "            \n",
    "end = time.time()\n",
    "\n",
    "print(f\"Time taken:{end-start}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e24e4f21-f177-4af8-84db-55ae96ae7ae2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98.86"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(teacher_model, train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "cdeffaf8-2c71-406a-a8ce-9c9fe1f7cfab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97.81"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(teacher_model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d430d80a-cd26-4195-8dda-cd04daf7e7e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StudentModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(StudentModel, self).__init__()\n",
    "        self.linear1 = nn.Linear(784, 50, dtype=torch.float64)\n",
    "        self.linear2 = nn.Linear(50, 10, dtype=torch.float64)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.linear1(x))\n",
    "        x = self.linear2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "fd89b901-b861-4efa-b94d-55282a87b7c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StudentModel(\n",
       "  (linear1): Linear(in_features=784, out_features=50, bias=True)\n",
       "  (linear2): Linear(in_features=50, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_model = StudentModel()\n",
    "student_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "cb0b806d-7e49-4dc6-b888-ed1361631b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = Adam(student_model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "5d1dae74-47be-4f25-a284-53e4297dc573",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.347399054312487\n",
      "Loss: 0.48183600122794135\n",
      "Loss: 0.20560929226882405\n",
      "Loss: 0.196136314844859\n",
      "Loss: 0.25455717524880234\n",
      "Loss: 0.11457593625663103\n",
      "Loss: 0.16190092655927735\n",
      "Loss: 0.10706857834372295\n",
      "Loss: 0.20032116716740372\n",
      "Loss: 0.11172894216186353\n",
      "Loss: 0.19089811885242675\n",
      "Loss: 0.18412750173453107\n",
      "Loss: 0.2434642570425792\n",
      "Loss: 0.15407006818880867\n",
      "Loss: 0.19223732260201168\n",
      "Loss: 0.061989243185216016\n",
      "Loss: 0.051927957107854236\n",
      "Loss: 0.06384545090455923\n",
      "Loss: 0.12476227588829371\n",
      "Loss: 0.08955146982993421\n",
      "Loss: 0.09095117290575683\n",
      "Loss: 0.19228158493777292\n",
      "Loss: 0.13068685103707914\n",
      "Loss: 0.12514300474909032\n",
      "Loss: 0.15192215447259427\n",
      "Loss: 0.05523088706264561\n",
      "Loss: 0.08446146593085185\n",
      "Loss: 0.05926083800673895\n",
      "Loss: 0.0742524875561164\n",
      "Loss: 0.11511030938619658\n",
      "Loss: 0.017762347602045314\n",
      "Loss: 0.10881318183425184\n",
      "Loss: 0.022470427425304477\n",
      "Loss: 0.07001898218221803\n",
      "Loss: 0.08773400918760618\n",
      "Loss: 0.02506472002957886\n",
      "Loss: 0.03591148655564282\n",
      "Loss: 0.04595865420028297\n",
      "Loss: 0.06722040491016618\n",
      "Loss: 0.058283380187254534\n",
      "Loss: 0.04592911873175469\n",
      "Loss: 0.10387846152611062\n",
      "Loss: 0.1225022170322522\n",
      "Loss: 0.04760868621398669\n",
      "Loss: 0.032397593889982895\n"
     ]
    }
   ],
   "source": [
    "student_model.train()\n",
    "for epoch in range(1, NUM_EPOCHS):\n",
    "    for i, (data, target) in enumerate(train_loader):\n",
    "        data = data.double()\n",
    "        data = data.view(BATCH_SIZE_TRAIN, -1)\n",
    "        data = data.to(device)\n",
    "        target = target.to(device)\n",
    "        \n",
    "        output = student_model(data)\n",
    "        loss = criterion(output, target)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if i % 100 == 0:\n",
    "            print(\"Loss:\", loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "9c5cd846-6ce8-4c40-b886-2d72ad6ebde4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98.598"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(student_model, train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "363465aa-d6e1-4e9b-91a3-756a3133fd35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97.1"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(student_model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "aced16fa-3fb5-4c5d-a5a4-e8fceb088685",
   "metadata": {},
   "outputs": [],
   "source": [
    "def distillation_loss(teacher_output, student_output, target, temp=1, alpha=0.5, beta=0.5):\n",
    "    student_output_log_prob = F.log_softmax(student_output / temp, dim=1)\n",
    "    teacher_output_prob = F.softmax(teacher_output / temp, dim=1)\n",
    "    return alpha * F.cross_entropy(student_output, target) + beta * -(teacher_output_prob*student_output_log_prob).sum(dim=1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "eef6b7b5-51e5-461f-9d9e-5fb1ae67197d",
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = torch.finfo(torch.float64).eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "09997d81-d199-4028-af72-d36824f9dfe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def distillation_loss_dirichlet(teacher_output_prob, student_output, target):\n",
    "    \"\"\"\n",
    "        This is a basic version of the distillation loss.\n",
    "        This does not scale the output using a temperature or incorporate a mixture of teacher loss and target loss.\n",
    "        *** Negating the log-likelihood to follow the convention of minimizing the loss function. ***\n",
    "    \"\"\"\n",
    "    return -((torch.sum((student_output - 1) * torch.log(teacher_output_prob + eps), dim=1) + torch.lgamma(torch.sum(student_output, dim=1) + eps) - torch.sum(torch.lgamma(student_output + eps), dim=1))).mean() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "3008e7e5-a0f0-4749-92d4-45cc8b702dde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StudentModel(\n",
       "  (linear1): Linear(in_features=784, out_features=50, bias=True)\n",
       "  (linear2): Linear(in_features=50, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_model_distilled = StudentModel()\n",
    "student_model_distilled.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "dda0e727-e4d0-4c8c-b414-566d665ebb17",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(student_model_distilled.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "2cf63e0c-f94a-4e0e-8e46-0d7647864565",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.3580268431516727\n",
      "Loss: 0.6107853313775403\n",
      "Loss: 0.55463149456736\n",
      "Loss: 0.6529141417873839\n",
      "Loss: 0.4835884293264955\n",
      "Loss: 0.49874910717174986\n",
      "Loss: 0.5202839596862426\n",
      "Loss: 0.4097256025562288\n",
      "Loss: 0.3231338011833757\n",
      "Loss: 0.3826480637080729\n",
      "Loss: 0.3359389219432365\n",
      "Loss: 0.27254007279638665\n",
      "Loss: 0.3411947537710217\n",
      "Loss: 0.5163640247243276\n",
      "Loss: 0.33480293263263294\n",
      "Loss: 0.40961410148506944\n",
      "Loss: 0.41234721783908024\n",
      "Loss: 0.29289605329798574\n",
      "Loss: 0.41800605280718833\n",
      "Loss: 0.4282348579891116\n",
      "Loss: 0.38715913418606573\n",
      "Loss: 0.3134492312038455\n",
      "Loss: 0.3884770284082473\n",
      "Loss: 0.30341899541394207\n",
      "Loss: 0.2518020574232445\n",
      "Loss: 0.3401087910735874\n",
      "Loss: 0.29358301241776064\n",
      "Loss: 0.27289855673361607\n",
      "Loss: 0.3477010625883886\n",
      "Loss: 0.3123522502314622\n",
      "Loss: 0.3329393184233002\n",
      "Loss: 0.32966112732820585\n",
      "Loss: 0.36341430756847637\n",
      "Loss: 0.2766805833454965\n",
      "Loss: 0.27680178190757937\n",
      "Loss: 0.3509351782688971\n",
      "Loss: 0.2723616804139621\n",
      "Loss: 0.31165877933740627\n",
      "Loss: 0.2652171241584098\n",
      "Loss: 0.31838635916025826\n",
      "Loss: 0.3413371348483851\n",
      "Loss: 0.32946287447087813\n",
      "Loss: 0.3431776667734908\n",
      "Loss: 0.32364293777654346\n",
      "Loss: 0.29848623770736793\n"
     ]
    }
   ],
   "source": [
    "student_model_distilled.train()\n",
    "teacher_model.eval()\n",
    "\n",
    "for epoch in range(1, NUM_EPOCHS):\n",
    "    for i, (data, target) in enumerate(train_loader):\n",
    "        data = data.double()\n",
    "        data = data.view(BATCH_SIZE_TRAIN, -1)\n",
    "        data = data.to(device)\n",
    "        target = target.to(device)        \n",
    "        student_output = student_model_distilled(data)\n",
    "        teacher_output = teacher_model(data)\n",
    "        loss = distillation_loss(teacher_output, student_output, target, temp=3, alpha=0.4, beta=0.6)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            print(\"Loss:\", loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "81703c13-ddd5-448d-9d23-44c8d7e5cf19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98.342"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(student_model_distilled, train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "ca67fd9f-faee-4158-bf65-86dd849500e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96.7"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(student_model_distilled, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "0ad023c6-69b1-4816-8553-c3303c949400",
   "metadata": {},
   "outputs": [],
   "source": [
    "def il(x):\n",
    "    return torch.where(x < 0, (1 / (1 - x)) + eps, x + 1 + eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "0fc75b09-73c8-4de2-b30a-6e2690b6847b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StudentModelDirichlet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(StudentModelDirichlet, self).__init__()\n",
    "        self.linear1 = nn.Linear(784, 50, dtype=torch.float64)\n",
    "        self.linear2 = nn.Linear(50, 10, dtype=torch.float64)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.linear1(x))\n",
    "        x = il(self.linear2(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "6aed3f24-0e6b-4ea5-a6d5-76e86de0120c",
   "metadata": {},
   "outputs": [],
   "source": [
    "student_model_distilled_dirichlet = StudentModelDirichlet()\n",
    "student_model_distilled_dirichlet.to(device)\n",
    "optimizer = Adam(student_model_distilled_dirichlet.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "96119dae-0216-40a2-b5ad-dfc7a164e5cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: -17.717303986340067\n",
      "MSE: 0.08658637135426829\n",
      "Loss: -146.93780363835742\n",
      "MSE: 0.0858176328888101\n",
      "Loss: -160.1516467405612\n",
      "MSE: 0.08502779704943841\n",
      "Loss: -151.5732022085047\n",
      "MSE: 0.08598026268752776\n",
      "Loss: -145.09532692669617\n",
      "MSE: 0.08080357296424963\n",
      "Loss: -155.395347442335\n",
      "MSE: 0.0786515033971438\n",
      "Loss: -146.2075900220333\n",
      "MSE: 0.0703130752894403\n",
      "Loss: -145.61893155397954\n",
      "MSE: 0.06273859935535837\n",
      "Loss: -136.10336262863788\n",
      "MSE: 0.051838923665585276\n",
      "Loss: -144.29814220012756\n",
      "MSE: 0.05042432139135245\n",
      "Loss: -169.1971692530504\n",
      "MSE: 0.046740488091019924\n",
      "Loss: -166.5030239855897\n",
      "MSE: 0.03755422379513372\n",
      "Loss: -160.61559037124567\n",
      "MSE: 0.04162129941551949\n",
      "Loss: -147.13621136140145\n",
      "MSE: 0.03671783803203076\n",
      "Loss: -137.09141544414652\n",
      "MSE: 0.038895164477791726\n",
      "Loss: -154.72762177310403\n",
      "MSE: 0.029404199037547384\n",
      "Loss: -168.80343136838664\n",
      "MSE: 0.02391109954544435\n",
      "Loss: -162.06933735138256\n",
      "MSE: 0.023925125080632815\n",
      "Loss: -168.43892053034907\n",
      "MSE: 0.02151434099695281\n",
      "Loss: -142.8460532984871\n",
      "MSE: 0.024280874137490617\n",
      "Loss: -164.14491543481847\n",
      "MSE: 0.020377945540058097\n",
      "Loss: -151.88360104474685\n",
      "MSE: 0.022880789215970355\n",
      "Loss: -156.7706441889921\n",
      "MSE: 0.021409777351544767\n",
      "Loss: -147.6425666798498\n",
      "MSE: 0.021548825471192967\n",
      "Loss: -150.92386013208167\n",
      "MSE: 0.017573838335903393\n",
      "Loss: -153.58729826569896\n",
      "MSE: 0.019596334548887474\n",
      "Loss: -149.8456196950313\n",
      "MSE: 0.01670120227540421\n",
      "Loss: -160.50237916359015\n",
      "MSE: 0.016331856618637487\n",
      "Loss: -154.74621908287824\n",
      "MSE: 0.01585008477793593\n",
      "Loss: -159.23783759847805\n",
      "MSE: 0.00940165174134541\n",
      "Loss: -147.93983161876068\n",
      "MSE: 0.009565022645662611\n",
      "Loss: -164.44152896287142\n",
      "MSE: 0.009428869807489648\n",
      "Loss: -169.31413201415205\n",
      "MSE: 0.010317368508178042\n",
      "Loss: -157.5926184605462\n",
      "MSE: 0.014497197189335712\n",
      "Loss: -156.15199153284937\n",
      "MSE: 0.012406472399315836\n",
      "Loss: -167.68964647680474\n",
      "MSE: 0.014456155754568503\n",
      "Loss: -158.9076297364696\n",
      "MSE: 0.011798173317225137\n",
      "Loss: -162.15213254030866\n",
      "MSE: 0.011333465705408123\n",
      "Loss: -161.678435231908\n",
      "MSE: 0.014147883904434251\n",
      "Loss: -164.00517975605436\n",
      "MSE: 0.011638223813477804\n",
      "Loss: -153.5699022600207\n",
      "MSE: 0.009994556964251581\n",
      "Loss: -158.93458262980494\n",
      "MSE: 0.008673705303784451\n",
      "Loss: -163.58536159074103\n",
      "MSE: 0.007705508142418359\n",
      "Loss: -144.96567328132937\n",
      "MSE: 0.011887365286533154\n",
      "Loss: -163.78076020201718\n",
      "MSE: 0.011649902389052072\n"
     ]
    }
   ],
   "source": [
    "student_model_distilled_dirichlet.train()\n",
    "teacher_model.eval()\n",
    "\n",
    "for epoch in range(1, NUM_EPOCHS):\n",
    "    for i, (data, target) in enumerate(train_loader):\n",
    "        data = data.double()\n",
    "        data = data.view(BATCH_SIZE_TRAIN, -1)\n",
    "        data = data.to(device)\n",
    "        target = target.to(device)\n",
    "        # target_one_hot_encoded = F.one_hot(target, num_classes=10)\n",
    "        student_output = student_model_distilled_dirichlet(data)\n",
    "        student_output.retain_grad()\n",
    "        \n",
    "        teacher_output = teacher_model(data)\n",
    "        teacher_output = F.softmax(teacher_output, dim=1)\n",
    "        loss = distillation_loss_dirichlet(teacher_output, student_output, target)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        \n",
    "        \n",
    "        # print(\"teacher_output\", teacher_output)\n",
    "        # print(\"student_output\", student_output)\n",
    "        # print(\"student_output sum\", student_output.sum())\n",
    "        # print(\"loss\", loss)\n",
    "        # if i % 100 == 0:\n",
    "        #     print(\"--------------\")\n",
    "        #     print(target)\n",
    "        #     print(student_output)\n",
    "        #     print(\"gradient\", student_output.grad)\n",
    "        # break\n",
    "        optimizer.step()\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            print(\"Loss:\", loss.item())\n",
    "            print(\"MSE:\", mean_squared_error(teacher_output, student_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "3bc10ec6-d4be-452d-9966-709369374cf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92.154"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(student_model_distilled_dirichlet, train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "9dbcc2c7-5d1a-421e-aaee-eff2273ebd73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92.14"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(student_model_distilled_dirichlet, test_loader, batch_size=100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
