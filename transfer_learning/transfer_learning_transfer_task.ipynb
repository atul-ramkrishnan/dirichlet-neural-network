{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e80cefd-ae76-4e56-ab93-9e6901c2cef0",
   "metadata": {},
   "source": [
    "# 4.3 Cifar-100 Transfer Task (but with MNIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9b4c1378-efbf-47e5-accd-d072cfc9de5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c475d8c2-8b76-4532-b579-6900a4796d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPS = torch.finfo(torch.float64).eps\n",
    "# EPS = 1e-8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "704ea8ee-a797-48e4-ad3e-5e86d7c3afc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def distillation_loss_generalized_dirichlet(teacher_output_prob, student_output_alpha, student_output_beta, verbose=False):\n",
    "    \"\"\"\n",
    "        This is a basic version of the distillation loss.\n",
    "        This does not scale the output using a temperature or incorporate a mixture of teacher loss and target loss.\n",
    "        *** Negating the log-likelihood to follow the convention of minimizing the loss function. ***\n",
    "    \"\"\"\n",
    "    teacher_output_prob = torch.clamp(teacher_output_prob, min=EPS)\n",
    "    student_output_alpha = torch.clamp(student_output_alpha, min=EPS)\n",
    "    student_output_beta = torch.clamp(student_output_beta, min=EPS)\n",
    "    d = student_output_alpha.shape[1]\n",
    "    loss = 0.0\n",
    "    for l in range(0, d - 1):\n",
    "        scaler = student_output_beta[:, l] - student_output_alpha[:, l + 1] - student_output_beta[:, l + 1]\n",
    "        sum_p = 0.0\n",
    "        for j in range(0, l + 1):\n",
    "            sum_p += teacher_output_prob[:, j]\n",
    "        sum_p = torch.clamp(sum_p, max=1-EPS)\n",
    "        if verbose:\n",
    "            print(\"sum_p:\", sum_p)\n",
    "        loss += scaler * torch.log(1 - sum_p)\n",
    "        \n",
    "    if verbose:\n",
    "        print(\"loss1:\", loss)\n",
    "    \n",
    "    sum_teacher_output_prob = torch.sum(teacher_output_prob, dim=1)\n",
    "    sum_teacher_output_prob = torch.clamp(sum_teacher_output_prob, max=1-EPS)\n",
    "    loss += (student_output_beta[:, d - 1] - 1) * torch.log(1 - sum_teacher_output_prob)\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"loss2:\", loss)\n",
    "    \n",
    "    loss += torch.sum(torch.lgamma(student_output_alpha + student_output_beta), dim=1) - torch.sum(torch.lgamma(student_output_alpha), dim=1) - \\\n",
    "            torch.sum(torch.lgamma(student_output_beta), dim=1) + torch.sum((student_output_alpha - 1) * torch.log(teacher_output_prob), dim=1)\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"loss3:\", loss)\n",
    "    \n",
    "    return -loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "885cf935-1bb7-4ca3-a10f-42f1c449593b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-81.5249)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha = torch.tensor([[0.0876, 0.0360, 0.0444, 0.0248, 0.0153, 0.0206, 0.0174, 0.0242, 0.0112]])\n",
    "beta = torch.tensor([[7.3526e+00, 2.2434e+01, 9.9446e+00, 9.6688e-02, 1.6363e-02, 4.5852e-02,\n",
    "        1.2404e-01, 1.5865e-02, 5.2503e+00]])\n",
    "\n",
    "P = torch.tensor([[2.5702e-07, 2.5177e-06, 2.2985e-05, 4.5485e-04, 2.8297e-07, 1.6700e-06,\n",
    "        1.8722e-11, 9.9125e-01, 1.8576e-07]])\n",
    "\n",
    "distillation_loss_generalized_dirichlet(P, alpha, beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c9813b9-dd18-4c8a-82cb-111aff2bb911",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-2.4812)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P = torch.tensor([[0.3, 0.3, 0.1]])\n",
    "\n",
    "alpha = torch.tensor([[2., 2., 3.]])\n",
    "\n",
    "beta = torch.tensor([[2., 3., 4.]])\n",
    "\n",
    "distillation_loss_generalized_dirichlet(P, alpha, beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "578701aa-9f80-45fd-93c2-2555fcc0a139",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-2.5903)\n"
     ]
    }
   ],
   "source": [
    "teacher_output_prob = torch.tensor([[0.25, 0.25, 0.3, 0.1]])\n",
    "student_output_alpha = torch.tensor([[1, 1, 1, 1]])\n",
    "student_output_beta = torch.tensor([[1, 1, 1, 1]])\n",
    "\n",
    "print(distillation_loss_generalized_dirichlet(teacher_output_prob, student_output_alpha, student_output_beta))\n",
    "# torch.isclose(distillation_loss_generalized_dirichlet(teacher_output_prob, student_output_alpha, student_output_beta), torch.tensor(-3.2834))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1d051f7-b36d-4ec9-85d8-23a90ed7ac1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-2.3671)\n"
     ]
    }
   ],
   "source": [
    "teacher_output_prob = torch.tensor([[0.25, 0.25, 0.25, 0.20]])\n",
    "student_output_alpha = torch.tensor([[1, 1, 1, 1]])\n",
    "student_output_beta = torch.tensor([[1, 1, 1, 1]])\n",
    "\n",
    "print(distillation_loss_generalized_dirichlet(teacher_output_prob, student_output_alpha, student_output_beta))\n",
    "# torch.isclose(distillation_loss_generalized_dirichlet(teacher_output_prob, student_output_alpha, student_output_beta), torch.tensor(-2.3671))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc25d520-39f6-4b79-a1d5-0a1340923cc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-2.4787)\n"
     ]
    }
   ],
   "source": [
    "teacher_output_prob = torch.tensor([[0.25, 0.25, 0.25, 0.20],\n",
    "                                   [0.25, 0.25, 0.3, 0.1]])\n",
    "student_output_alpha = torch.tensor([[1, 1, 1, 1],\n",
    "                                    [1, 1, 1, 1]])\n",
    "student_output_beta = torch.tensor([[1, 1, 1, 1],\n",
    "                                   [1, 1, 1, 1]])\n",
    "\n",
    "print(distillation_loss_generalized_dirichlet(teacher_output_prob, student_output_alpha, student_output_beta))\n",
    "# torch.isclose(distillation_loss_generalized_dirichlet(teacher_output_prob, student_output_alpha, student_output_beta), torch.tensor(-2.3671))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c51bde60-cd19-4ee1-a2eb-9a46509e2af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7ba4c3ad-f4c6-4eee-8d9b-466aea161b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE_TRAIN = 100\n",
    "BATCH_SIZE_VAL = 100\n",
    "BATCH_SIZE_TEST = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e69371c4-c441-4fca-90cd-ffa8f4e37207",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = torchvision.datasets.MNIST('./', train=True, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,))\n",
    "                             ]))\n",
    "testset = torchvision.datasets.MNIST('./', train=False, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,))\n",
    "                             ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c38c2681-c778-4c82-bf26-694c91c17faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_subset, val_subset = torch.utils.data.random_split(\n",
    "        trainset, [50000, 10000], generator=torch.Generator().manual_seed(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6ee27b62-6537-4e79-bd29-13e65a09fa78",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset=train_subset, shuffle=False, batch_size=BATCH_SIZE_TRAIN)\n",
    "val_loader = DataLoader(dataset=val_subset, shuffle=False, batch_size=BATCH_SIZE_VAL)\n",
    "test_loader = DataLoader(dataset=testset, shuffle=False, batch_size=BATCH_SIZE_TEST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "82a7e410-e9a2-4c3c-ab4e-3e72eb7e2cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, dataset, batch_size=100, max_ex=0):\n",
    "    model.eval()\n",
    "    acc = 0\n",
    "    N = len(dataset) * batch_size\n",
    "    for i, (features, labels) in enumerate(dataset):\n",
    "        features = features.view(batch_size, -1)\n",
    "        features = features.to(device)\n",
    "        features = features.double()\n",
    "        labels = labels.to(device)\n",
    "        scores = model(features)\n",
    "        # print(labels)\n",
    "        # print(scores)\n",
    "        pred = torch.argmax(scores, dim=1)\n",
    "        acc += torch.sum(torch.eq(pred, labels)).item()\n",
    "        if max_ex != 0 and i >= max_ex:\n",
    "            break\n",
    "    # print(i)\n",
    "    return (acc * 100 / ((i+1) * batch_size) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fb026954-8821-4c74-b85b-672f0119aafd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_generalized_dirichlet(model, dataset, batch_size=100, max_ex=0):\n",
    "    model.eval()\n",
    "    acc = 0\n",
    "    N = len(dataset) * batch_size\n",
    "    for i, (features, labels) in enumerate(dataset):\n",
    "        features = features.view(batch_size, -1)\n",
    "        features = features.to(device)\n",
    "        features = features.double()\n",
    "        labels = labels.to(device)\n",
    "        output_alpha, output_beta = model(features)\n",
    "        \n",
    "        output = output_alpha / (output_alpha + output_beta)\n",
    "        d = output_alpha.shape[1]\n",
    "        for l in range(0, d):\n",
    "            prod = 1.\n",
    "            for k in range(0, l):\n",
    "                prod *= output_beta[:, k] / (output_alpha[:, k] + output_beta[:, k])\n",
    "            output[:, l] *= prod\n",
    "        \n",
    "        # print(output.shape)\n",
    "        # print((1 - torch.unsqueeze(torch.sum(output, dim=1), dim=1)).shape)\n",
    "        torch.concat((output, 1 - torch.unsqueeze(torch.sum(output, dim=1), dim=1)), dim=1)\n",
    "        pred = torch.argmax(output, dim=1)\n",
    "        acc += torch.sum(torch.eq(pred, labels)).item()\n",
    "        if max_ex != 0 and i >= max_ex:\n",
    "            break\n",
    "    # print(i)\n",
    "    return (acc * 100 / ((i+1) * batch_size) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e6bd7ae2-6204-43f0-9b3a-6eb659c260f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_squared_error(teacher_output_prob, student_output_alpha, student_output_beta):\n",
    "    \"\"\"\n",
    "    teacher_output_prob: output of teacher model after applying softmax (N, d)\n",
    "    student_output_alpha: output of student model (alpha) (N, d)\n",
    "    student_output_beta: output of student model (beta) (N, d)\n",
    "    labels are of size d+1\n",
    "    \"\"\"\n",
    "    \n",
    "    output = student_output_alpha / (student_output_alpha + student_output_beta)\n",
    "    d = student_output_alpha.shape[1]\n",
    "    for l in range(0, d):\n",
    "        prod = 1.\n",
    "        for k in range(0, l):\n",
    "            prod *= student_output_beta[:, k] / (student_output_alpha[:, k] + student_output_beta[:, k])\n",
    "        output[:, l] *= prod\n",
    "    # torch.concat((output, 1 - torch.unsqueeze(torch.sum(output, dim=1), dim=1)), dim=1)\n",
    "    return F.mse_loss(teacher_output_prob, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ce41afa7-84ec-4c00-8108-dd093f2ffd98",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TeacherModel(nn.Module):\n",
    "    def __init__(self, dropout=0.5):\n",
    "        super(TeacherModel, self).__init__()\n",
    "        self.linear1 = nn.Linear(784, 400, dtype=torch.float64)\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        self.linear2 = nn.Linear(400, 100, dtype=torch.float64)\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        self.linear3 = nn.Linear(100, 10, dtype=torch.float64)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.linear1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.linear2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.linear3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ad78a9e5-9a47-4034-be5a-2fa6e53dd93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 10\n",
    "lr = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bc8c4c80-110b-49a5-b6b3-39fb74cafb48",
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_model = TeacherModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f49dd59b-5915-4841-b720-af67c0b1fa3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = Adam(teacher_model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "81aa65b2-d419-47a4-95a0-1dcc018dface",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.321927346979167\n",
      "Loss: 0.5406929891843757\n",
      "Loss: 0.2381379094473123\n",
      "Loss: 0.3982020766564197\n",
      "Loss: 0.30027667412171044\n",
      "Loss: 0.2506617631915267\n",
      "Loss: 0.25247357530419334\n",
      "Loss: 0.26705201346340723\n",
      "Loss: 0.2682749314215985\n",
      "Loss: 0.24918368343072367\n",
      "Loss: 0.1270754774954089\n",
      "Loss: 0.14980813776985377\n",
      "Loss: 0.20738678384495265\n",
      "Loss: 0.25045025578714764\n",
      "Loss: 0.17218106027782698\n",
      "Loss: 0.14713575216159125\n",
      "Loss: 0.21087226725638808\n",
      "Loss: 0.1050023911637876\n",
      "Loss: 0.15179182134546823\n",
      "Loss: 0.09892041876898022\n",
      "Loss: 0.13389585536363366\n",
      "Loss: 0.08284455345968224\n",
      "Loss: 0.08929186971024118\n",
      "Loss: 0.24426680015342034\n",
      "Loss: 0.12078413082162433\n",
      "Loss: 0.10699673931127923\n",
      "Loss: 0.1339071434258485\n",
      "Loss: 0.04593023289810023\n",
      "Loss: 0.1692386692115836\n",
      "Loss: 0.08393953972107006\n",
      "Loss: 0.17554591433020306\n",
      "Loss: 0.24404950196258698\n",
      "Loss: 0.06333964940669734\n",
      "Loss: 0.11967236043496766\n",
      "Loss: 0.1140977839833482\n",
      "Loss: 0.15496087640197134\n",
      "Loss: 0.14016759577865012\n",
      "Loss: 0.08243407957765939\n",
      "Loss: 0.06031295837033196\n",
      "Loss: 0.09393428346576309\n",
      "Loss: 0.14711063667112323\n",
      "Loss: 0.08102708418614156\n",
      "Loss: 0.07714690361473045\n",
      "Loss: 0.14653795900843067\n",
      "Loss: 0.07166162867268616\n"
     ]
    }
   ],
   "source": [
    "teacher_model.to(device)\n",
    "teacher_model.train()\n",
    "for epoch in range(1, NUM_EPOCHS):\n",
    "    for i, (data, target) in enumerate(train_loader):\n",
    "        data = data.view(BATCH_SIZE_TRAIN, -1)\n",
    "        data = data.to(device)\n",
    "        data = data.double()\n",
    "        target = target.to(device)\n",
    "        \n",
    "        output = teacher_model(data)\n",
    "        loss = criterion(output, target)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if i % 100 == 0:\n",
    "            print(\"Loss:\", loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "496006ac-b309-4437-9683-b3bfd6c414a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98.69"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(teacher_model, train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8eeca188-3636-441a-b139-aa6045771787",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97.69"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(teacher_model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "15a4781b-54b1-4720-9f6c-07c0023ff219",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StudentModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(StudentModel, self).__init__()\n",
    "        self.linear1 = nn.Linear(784, 50, dtype=torch.float64)\n",
    "        self.linear2 = nn.Linear(50, 10, dtype=torch.float64)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.linear1(x))\n",
    "        x = self.linear2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6d31d519-611e-4fa0-aee0-676c4b20bb97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StudentModel(\n",
       "  (linear1): Linear(in_features=784, out_features=50, bias=True)\n",
       "  (linear2): Linear(in_features=50, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_model = StudentModel()\n",
    "student_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1ab7f6b4-faa0-407c-9f9b-8ddf1b8eaa60",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = Adam(student_model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "db24054e-4470-460c-931d-519f7da57a28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.270961151718689\n",
      "Loss: 0.41900789647262604\n",
      "Loss: 0.2354292438152886\n",
      "Loss: 0.2867501562507435\n",
      "Loss: 0.22119320720610222\n",
      "Loss: 0.2604503886990442\n",
      "Loss: 0.22001783687898618\n",
      "Loss: 0.1398574933871171\n",
      "Loss: 0.20669469511616356\n",
      "Loss: 0.18165706807890777\n",
      "Loss: 0.22949117268237146\n",
      "Loss: 0.16986984730832538\n",
      "Loss: 0.11333973193393738\n",
      "Loss: 0.18944355834871293\n",
      "Loss: 0.13694604067818372\n",
      "Loss: 0.19334442112836392\n",
      "Loss: 0.13648027180562702\n",
      "Loss: 0.08832691675831245\n",
      "Loss: 0.16430023327569676\n",
      "Loss: 0.10590618842016253\n",
      "Loss: 0.1659931083403088\n",
      "Loss: 0.11721715770561181\n",
      "Loss: 0.07155797104486906\n",
      "Loss: 0.14652881334524653\n",
      "Loss: 0.08275959090987998\n",
      "Loss: 0.14321553095394457\n",
      "Loss: 0.10039981932920196\n",
      "Loss: 0.05246813914993325\n",
      "Loss: 0.1482203384941135\n",
      "Loss: 0.06945801219798503\n",
      "Loss: 0.1248082182149465\n",
      "Loss: 0.08646373454426357\n",
      "Loss: 0.04665274424654235\n",
      "Loss: 0.13533362445742536\n",
      "Loss: 0.054295771366164286\n",
      "Loss: 0.11142811551188653\n",
      "Loss: 0.07861776679348634\n",
      "Loss: 0.03950754803068454\n",
      "Loss: 0.1331664928541246\n",
      "Loss: 0.0411890592390206\n",
      "Loss: 0.10432379275281269\n",
      "Loss: 0.06643553751729325\n",
      "Loss: 0.03849283996868228\n",
      "Loss: 0.1295735680224294\n",
      "Loss: 0.035331336133578695\n"
     ]
    }
   ],
   "source": [
    "student_model.train()\n",
    "for epoch in range(1, NUM_EPOCHS):\n",
    "    for i, (data, target) in enumerate(train_loader):\n",
    "        data = data.view(BATCH_SIZE_TRAIN, -1)\n",
    "        data = data.to(device)\n",
    "        data = data.double()\n",
    "        target = target.to(device)\n",
    "        \n",
    "        output = student_model(data)\n",
    "        loss = criterion(output, target)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if i % 100 == 0:\n",
    "            print(\"Loss:\", loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f271528e-cec0-4de6-842c-93ebc8ce3986",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98.212"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(student_model, train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cba85fe9-0efc-4698-b30f-9730e6a3b1e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96.62"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(student_model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "676decde-16da-43c0-baaa-66a3563128a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def il(x):\n",
    "    return torch.where(x < 0, (1 / (1 - x)), x + 1) + EPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "24cc84ba-7f1a-41c9-84b8-f79eb92c2357",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StudentModelGeneralizedDirichlet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(StudentModelGeneralizedDirichlet, self).__init__()\n",
    "        self.linear1 = nn.Linear(784, 50, dtype=torch.float64)\n",
    "        self.output_alpha = nn.Linear(50, 9, dtype=torch.float64)\n",
    "        self.output_beta = nn.Linear(50, 9, dtype=torch.float64) \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.linear1(x))\n",
    "        output_alpha = il(self.output_alpha(x))\n",
    "        output_beta = il(self.output_beta(x))\n",
    "        return output_alpha, output_beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f71619b9-246c-4912-8be8-2fcabbbf985b",
   "metadata": {},
   "outputs": [],
   "source": [
    "student_model_distilled_generalized_dirichlet = StudentModelGeneralizedDirichlet()\n",
    "student_model_distilled_generalized_dirichlet.to(device)\n",
    "optimizer = Adam(student_model_distilled_generalized_dirichlet.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f2608c14-3fd5-49f8-9685-e5c89353723c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: -52.17779732390217\n",
      "MSE: 0.11166792284739137\n",
      "Loss: -147.89911393376394\n",
      "MSE: 0.04025670339046927\n",
      "Loss: -149.11625976377948\n",
      "MSE: 0.024466450215527343\n",
      "Loss: -149.70077063133738\n",
      "MSE: 0.01530498505556994\n",
      "Loss: -150.07120507661134\n",
      "MSE: 0.011611725505929073\n",
      "Loss: -150.3110254001964\n",
      "MSE: 0.009305463769942159\n",
      "Loss: -150.48851102127549\n",
      "MSE: 0.008052968771008931\n",
      "Loss: -150.63948959655426\n",
      "MSE: 0.006918096175341358\n",
      "Loss: -150.76266200454933\n",
      "MSE: 0.006408594751734392\n"
     ]
    }
   ],
   "source": [
    "student_model_distilled_generalized_dirichlet.train()\n",
    "teacher_model.eval()\n",
    "\n",
    "for epoch in range(1, NUM_EPOCHS):\n",
    "    for i, (data, target) in enumerate(train_loader):\n",
    "        data = data.view(BATCH_SIZE_TRAIN, -1)\n",
    "        data = data.to(device)\n",
    "        data = data.double()\n",
    "        # print(data.dtype)\n",
    "        # print(target.dtype)\n",
    "        target = target.to(device)\n",
    "        # target_one_hot_encoded = F.one_hot(target, num_classes=10)\n",
    "        teacher_output = teacher_model(data)\n",
    "        teacher_output = F.softmax(teacher_output, dim=1)\n",
    "        teacher_output = teacher_output[:, :-1]\n",
    "        student_output_alpha, student_output_beta = student_model_distilled_generalized_dirichlet(data)\n",
    "        # print(student_output_alpha)\n",
    "        # print(student_output_beta)\n",
    "        # print(teacher_output[0])\n",
    "        # student_output.retain_grad()\n",
    "        \n",
    "        \n",
    "        loss = distillation_loss_generalized_dirichlet(teacher_output, student_output_alpha, student_output_beta, verbose=False)\n",
    "        if i == 0:\n",
    "            print(\"Loss:\", loss.item())\n",
    "            print(\"MSE:\", mean_squared_error(teacher_output, student_output_alpha, student_output_beta).item())\n",
    "            # print(\"alpha\", student_output_alpha[0,])\n",
    "            # print(\"beta\", student_output_beta[0,])\n",
    "            # print(\"P\", teacher_output[0, ])\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8c1c032a-6944-43c6-83f7-24c1a6e43c21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84.768"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_generalized_dirichlet(student_model_distilled_generalized_dirichlet, train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3d04e891-334a-4fab-9ffa-6555f05a2794",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84.47"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_generalized_dirichlet(student_model_distilled_generalized_dirichlet, test_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
